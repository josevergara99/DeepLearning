{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "NPL-imdb.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c2TxYVOOy7q",
        "colab_type": "text"
      },
      "source": [
        "# IMDB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7pYx8PYOy7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LpWM97Oy8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81RD0WnTOy8M",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODKTahG7Oy8O",
        "colab_type": "text"
      },
      "source": [
        "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
        "\n",
        "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLswtTPkOy8Q",
        "colab_type": "code",
        "outputId": "2e17ef43-a4d6-4920-8af0-29778fca7430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)\n",
        "path.ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://files.fast.ai/data/examples/imdb_sample.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb_sample/texts.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umQNRcG0Oy8Z",
        "colab_type": "text"
      },
      "source": [
        "It only contains one csv file, let's have a look at it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P17VKHGLOy8a",
        "colab_type": "code",
        "outputId": "d27524f1-e7f5-4dd2-9a54-fabc056e2906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv(path/'texts.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1  positive  This is a extremely well-made film. The acting...     False\n",
              "2  negative  Every once in a long while a movie will come a...     False\n",
              "3  positive  Name just says it all. I watched this movie wi...     False\n",
              "4  negative  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL2cpW2YOy8h",
        "colab_type": "code",
        "outputId": "a5576dba-5474-4e24-c471-d8ffb97f79a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df['text'][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1XFKxlQOy8p",
        "colab_type": "text"
      },
      "source": [
        "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft6-xPatOy8r",
        "colab_type": "code",
        "outputId": "ab3668ea-debf-42ba-cd35-95848ff3eccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data_lm = TextDataBunch.from_csv(path, 'texts.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpNMGYGzOy8y",
        "colab_type": "text"
      },
      "source": [
        "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
        "\n",
        "Before we delve into the explanations, let's take the time to save the things that were calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tO-tr0jOy8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYYxKNv4Oy85",
        "colab_type": "text"
      },
      "source": [
        "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKzLc3pZOy87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGTgCOFHOy9C",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfq_EwxJOy9D",
        "colab_type": "text"
      },
      "source": [
        "The first step of processing we make the texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
        "\n",
        "- we need to take care of punctuation\n",
        "- some words are contractions of two different words, like isn't or don't\n",
        "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
        "\n",
        "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_QulobVOy9E",
        "colab_type": "code",
        "outputId": "8d78d171-5f6a-48f1-e597-8dd926334bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
        "data.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n  xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , steaming bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj sydney , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n  xxmaj it 's usually satisfying to watch a film director change his style /</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this film sat on my xxmaj xxunk for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the xxunk - up xxunk of xxmaj new xxmaj yorkers . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj many neglect that this is n't just a classic due to the fact that it 's the first xxup 3d game , or even the first xxunk - up . xxmaj it 's also one of the first stealth games , one of the xxunk definitely the first ) truly claustrophobic games , and just a pretty well - rounded gaming experience in general . xxmaj with graphics</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos i really wanted to love this show . i truly , honestly did . \\n \\n  xxmaj for the first time , gay viewers get their own version of the \" xxmaj the xxmaj bachelor \" . xxmaj with the help of his obligatory \" hag \" xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFUabyDOy9K",
        "colab_type": "text"
      },
      "source": [
        "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
        "- the \"'s\" are grouped together in one token\n",
        "- the contractions are separated like this: \"did\", \"n't\"\n",
        "- content has been cleaned for any HTML symbol and lower cased\n",
        "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjOlAFwOOy9L",
        "colab_type": "text"
      },
      "source": [
        "### Numericalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRPG87IQOy9N",
        "colab_type": "text"
      },
      "source": [
        "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
        "\n",
        "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woVAQcZhOy9P",
        "colab_type": "code",
        "outputId": "27e81841-7d92-48d5-97b2-e75a42ba4bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data.vocab.itos[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xxunk',\n",
              " 'xxpad',\n",
              " 'xxbos',\n",
              " 'xxeos',\n",
              " 'xxfld',\n",
              " 'xxmaj',\n",
              " 'xxup',\n",
              " 'xxrep',\n",
              " 'xxwrep',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXZhXSMnOy9a",
        "colab_type": "text"
      },
      "source": [
        "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le0ndGHZOy9c",
        "colab_type": "code",
        "outputId": "4ae47833-6873-4bb0-e266-1a1ce7b37710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.train_ds[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text [   2   19  165   39 ... 1015   15   17   10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzHAwY-1Oy9n",
        "colab_type": "text"
      },
      "source": [
        "But the underlying data is all numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qwIRNLSOy9q",
        "colab_type": "code",
        "outputId": "2146b2f7-729e-47aa-8d83-2722e28a43ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.train_ds[0][0].data[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,   19,  165,   39,   13,  208,  367,   14,  106, 1969])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMUuGVkKOy92",
        "colab_type": "text"
      },
      "source": [
        "### With the data block API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8PNGvhQOy94",
        "colab_type": "text"
      },
      "source": [
        "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
        "\n",
        "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the various arguments to pass will appear in the step they're revelant, so it'll be more readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvggcCDoOy96",
        "colab_type": "code",
        "outputId": "ef4889c8-1e16-4d32-c109-2b8d3f884e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
        "                .split_from_df(col=2)\n",
        "                .label_from_df(cols=0)\n",
        "                .databunch())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtLkqdHVOy-H",
        "colab_type": "text"
      },
      "source": [
        "## Language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_sq5bZ4Oy-J",
        "colab_type": "text"
      },
      "source": [
        "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32PQCjDmOy-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz8PHHlYOy-Q",
        "colab_type": "text"
      },
      "source": [
        "Now let's grab the full dataset for what follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SmjxgfjOy-R",
        "colab_type": "code",
        "outputId": "50cb2f2d-5a69-41c9-a0a9-444b24594693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "path.ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/tmp_lm'),\n",
              " PosixPath('/root/.fastai/data/imdb/train'),\n",
              " PosixPath('/root/.fastai/data/imdb/unsup'),\n",
              " PosixPath('/root/.fastai/data/imdb/README'),\n",
              " PosixPath('/root/.fastai/data/imdb/imdb.vocab'),\n",
              " PosixPath('/root/.fastai/data/imdb/tmp_clas'),\n",
              " PosixPath('/root/.fastai/data/imdb/test')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv8dX9A2Oy-X",
        "colab_type": "code",
        "outputId": "3fb17f84-ff74-4470-b142-bd7642fc54c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(path/'train').ls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/root/.fastai/data/imdb/train/neg'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/pos'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/unsupBow.feat'),\n",
              " PosixPath('/root/.fastai/data/imdb/train/labeledBow.feat')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVQ3TmQoOy-f",
        "colab_type": "text"
      },
      "source": [
        "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
        "\n",
        "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipedia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word is, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
        "\n",
        "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust the parameters of our model by a little bit. Plus there might be some words that would be extremely common in the reviews dataset but would be barely present in wikipedia, and therefore might not be part of the vocabulary the model was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59MTt7XgOy-g",
        "colab_type": "text"
      },
      "source": [
        "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C_j22kIOy-i",
        "colab_type": "code",
        "outputId": "da1959c0-76ce-4d2e-cfd1-b50c0b7935c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data_lm = (TextList.from_folder(path)\n",
        "           #Inputs: all the text files in path\n",
        "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
        "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
        "            .split_by_rand_pct(0.1)\n",
        "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
        "            .label_for_lm()           \n",
        "           #We want to do a language model so we label accordingly\n",
        "            .databunch(bs=bs))\n",
        "data_lm.save('data_lm.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAC2nZMMOy-n",
        "colab_type": "text"
      },
      "source": [
        "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
        "\n",
        "The line before being a bit long, we want to load quickly the final ids by using the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Px5qnovOy-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data(path, 'data_lm.pkl', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYTg9gaTOy-t",
        "colab_type": "code",
        "outputId": "11852abb-b129-49fc-b6db-b2791677dafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "data_lm.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>joe xxmaj d'amato using his real name for a change ) , is a clumsy mix of the supernatural , murder / mystery , and pretentious arty rubbish , the likes of which will probably appeal to those who admire trippy 70s garbage such as xxmaj jess xxmaj franco 's more bizarre efforts , but which had me struggling to remain conscious . \\n \\n  xxmaj opening with a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>is an horror ! ! xxmaj imagine ! xxmaj gary xxmaj busey in another low budget movie , with an incredibly bad scenario ... isn't that a nightmare ? xxmaj no ( well yes ) , it is xxmaj plato 's run xxrep 11 . i give it * out of xxrep 5 * . xxbos xxmaj this film was a big disappointment . \\n \\n  i take the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>where the protagonists get super powers in theirs dreams , it started to become childish . xxmaj this sh*t should have been rated xxup pg or xxup pg-13 rather than xxup r. i expected to see some very mature stuff but it was only for the 1 / 3 of the film . xxmaj the rest are for little kids . xxmaj plus it 's focused too much on xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>used to directors taking stories from other cultures and adapting them to their own culture . xxmaj the spate of xxmaj american remakes of foreign films is a prime example , but then again , xxmaj xxunk turned xxmaj kurosawa 's xxmaj seven xxmaj samurai into xxmaj the xxmaj magnificent xxmaj seven with splendid results , and xxmaj kurosawa transferred xxmaj shakespeare 's xxmaj macbeth into xxmaj japan to make</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>? \" xxmaj there are a couple of problems here . xxmaj firstly , there is the probable chance that i 've not seen it and thus , i ruin my reputation . xxmaj secondly , i could trash the movie in question without realising that it 's actually their favourite . xxmaj lastly , i could be given dvds to watch so they can judge my opinion . xxmaj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cnb8pHwOy-y",
        "colab_type": "text"
      },
      "source": [
        "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t2rMcm5Oy-z",
        "colab_type": "code",
        "outputId": "928e6287-592a-4e19-ea92-886383f89272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7L-wh9Oy-7",
        "colab_type": "code",
        "outputId": "22662a31-9250-4ad3-902a-8ec0ba863f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='99' class='' max='8052' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      1.23% [99/8052 00:16<22:33 11.9220]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unu9yw5eOy_A",
        "colab_type": "code",
        "outputId": "924d1a64-7ccb-452b-f0fc-f926bd774c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "learn.recorder.plot(skip_end=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaKniF5lOy_F",
        "colab_type": "code",
        "outputId": "ad6b9656-26a7-4b5f-c6a6-bc1cabe2e8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.185551</td>\n",
              "      <td>4.026449</td>\n",
              "      <td>0.294948</td>\n",
              "      <td>23:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PN0jQWHOy_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fit_head')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL5rUQdkOy_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('fit_head');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePtEbTPZOy_O",
        "colab_type": "text"
      },
      "source": [
        "To complete the fine-tuning, we can then unfeeze and launch a new training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWsXUI8POy_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcn_ojefOy_R",
        "colab_type": "code",
        "outputId": "5f7f7071-3a18-4551-bd6e-565850d6a93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.828341</td>\n",
              "      <td>3.816571</td>\n",
              "      <td>0.317255</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.811678</td>\n",
              "      <td>3.775031</td>\n",
              "      <td>0.324466</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.798003</td>\n",
              "      <td>3.746073</td>\n",
              "      <td>0.328929</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.715668</td>\n",
              "      <td>3.711177</td>\n",
              "      <td>0.333136</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.658008</td>\n",
              "      <td>3.678977</td>\n",
              "      <td>0.336868</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.600554</td>\n",
              "      <td>3.653771</td>\n",
              "      <td>0.339861</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.529134</td>\n",
              "      <td>3.635536</td>\n",
              "      <td>0.342151</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.465633</td>\n",
              "      <td>3.624398</td>\n",
              "      <td>0.343748</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.380771</td>\n",
              "      <td>3.621438</td>\n",
              "      <td>0.344308</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.369470</td>\n",
              "      <td>3.623055</td>\n",
              "      <td>0.344239</td>\n",
              "      <td>26:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsyBuLnxOy_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fine_tuned')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChInKvxZOy_W",
        "colab_type": "text"
      },
      "source": [
        "How good is our model? Well let's try to see what it predicts after a few given words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7567ZAEbOy_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('fine_tuned');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-An8wEqOy_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = \"I liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssKz5xb3Oy_a",
        "colab_type": "code",
        "outputId": "9389f090-df03-4c6f-8538-96cc9a6d552d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I liked this movie because it was sort of a Brooklyn - Jewish story . It 's not an \" . \" i was n't expecting much . It was n't . The acting , the story , the\n",
            "I liked this movie because it reminded me of modest movies like Better Off Dead and The Grey Zone . They do n't get much of a budget at all and they are n't that big of an\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXAlOFVeOy_e",
        "colab_type": "text"
      },
      "source": [
        "We have to save not only the model, but also its encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNlO3YZdOy_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHXfIa_yOy_h",
        "colab_type": "text"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T0Ys-_uOy_i",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogPBKhmOy_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDlSy6igOy_k",
        "colab_type": "code",
        "outputId": "553c8164-a0cc-468b-9fce-72ede6a9d640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
        "             #grab all the text files in path\n",
        "             .split_by_folder(valid='test')\n",
        "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
        "             .label_from_folder(classes=['neg', 'pos'])\n",
        "             #label them all with their folders\n",
        "             .databunch(bs=bs))\n",
        "\n",
        "data_clas.save('data_clas.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOGEPSa8Oy_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas = load_data(path, 'data_clas.pkl', bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJjmiplEOy_p",
        "colab_type": "code",
        "outputId": "d8293c56-1929-4474-869b-4a7e71101923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos \" a xxmaj damsel in xxmaj distress \" is definitely not one of xxmaj fred xxmaj astaire 's better musicals . xxmaj but even xxmaj astaire 's bad films always had some good moments . \\n \\n  xxmaj in \" xxmaj damsel , \" xxmaj astaire is xxmaj jerry xxmaj halliday , an xxmaj american musical star who is in xxmaj london on a personal appearance tour .</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj first off , let me say that i am a great believer in xxmaj xxunk stuff . i see it as a way to continue a good show long after it has been cancelled . xxmaj star xxmaj trek xxmaj voyages and xxmaj star xxmaj wars xxmaj revelations are examples of decent efforts . xxmaj so i have a soft - spot for xxunk stuff that means i</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj the best film on the battle of xxmaj san xxmaj antonio , xxmaj texas in xxmaj march 1836 , was xxmaj john xxmaj wayne 's 1960 epic xxup the xxup alamo . xxmaj in a one shot job as director producer , that temporarily financially strapped him , xxmaj wayne demonstrated that he was talented in movie making outside of his icon - like acting ability personifying the</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj linking story : another first - time viewing for me and , again , this is one of the most popular of the xxmaj amicus anthologies - and it 's easy to see why , though i realize how the film 's rather meaningless title could be misleading for some ; i certainly fancied director xxmaj peter xxmaj duffell 's choice - xxup death xxup and xxup the</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFbXAEWCOy_r",
        "colab_type": "text"
      },
      "source": [
        "We can then create a model to classify those reviews and load the encoder we saved before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB28zQh0Oy_r",
        "colab_type": "code",
        "outputId": "e076c023-a485-4140-8754-a26702c60945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('fine_tuned_enc')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (25000 items)\n",
              "x: TextList\n",
              "xxbos ' i do n't understand . xxmaj none of this makes any sense ! ' , exclaims one exasperated character towards the end of xxmaj death xxmaj smiles at xxmaj murder . xxmaj having just sat through this thoroughly confusing mess of a movie , i know exactly how he feels . xxmaj the story , by the film 's director xxmaj aristide xxmaj xxunk ( good old xxmaj joe xxmaj d'amato using his real name for a change ) , is a clumsy mix of the supernatural , murder / mystery , and pretentious arty rubbish , the likes of which will probably appeal to those who admire trippy 70s garbage such as xxmaj jess xxmaj franco 's more bizarre efforts , but which had me struggling to remain conscious . \n",
              " \n",
              "  xxmaj opening with a hunchback mourning the death of his beautiful sister ( with whom he had been having an incestuous affair , before eventually losing her to a dashing doctor ) , xxmaj death xxmaj smiles at xxmaj murder soon becomes very confusing when the very same woman ( played by xxmaj ewa xxmaj aulin , who stars in the equally strange ' xxmaj death xxmaj laid an xxmaj egg ' ) is seen alive and kicking , the sole survivor of a coach accident that occurs outside the estate of xxmaj walter and xxmaj eva von xxmaj xxunk . xxmaj after being invited to stay and recuperate in their home , where she is tended to by creepy xxmaj dr. xxmaj sturges ( xxmaj klaus xxmaj kinski in a throwaway role ) , the comely lass begins love affairs with both xxmaj mr. and xxmaj mrs. xxmaj xxunk ( meaning that viewers are treated to some brief but welcome scenes of nookie and lesbian lovin' ) . \n",
              " \n",
              "  ' xxmaj so far , so good ' , i thought to myself at this point , ' we 've had xxunk , incest , some blood and guts , and gratuitous female xxunk ingredients of a great trashy xxmaj euro - horror ; what follows , however , is a lame attempt by xxmaj xxunk to combine giallo style killings , ghostly goings on , and even elements from xxmaj edgar xxmaj allan xxmaj poe 's ' xxmaj the xxmaj black xxmaj cat ' , to tell a very silly , utterly bewildering , and ultimately extremely boring tale of revenge from beyond the grave . \n",
              " \n",
              "  xxmaj this film seems to have quite few admirers here on imdb , but given the choice , i would much rather watch one of the director 's sleazier movies from later in his career ; i guess incomprehensible , meandering , surreal 70s xxmaj gothic horror just ai n't my thing ! 2.5 out of 10 ( purely for the cheesy gore and xxunk ) , rounded up to 3 for imdb .,xxbos xxmaj this movie seemed like it was going to be better than it ended up being . xxmaj the cinematography is good , the acting seemed solid , the dialogue was n't too stiff ... but then about twenty minutes in there 's this long scene with a xxmaj doctor who you know is actually a patient at the asylum pretending to be a xxmaj doctor - and it just goes south from there . \n",
              " \n",
              "  xxmaj on top of that , the demon is about the silliest looking xxunk since the xxmaj godzilla - looking thing in xxmaj curse of the xxmaj demon . xxmaj there 's also some odd demon worshippers who wear masks that look like the exploding teens from the beginning of xxmaj logan 's xxmaj run . \n",
              " \n",
              "  xxmaj in the end , the cinematography could n't save this movie . xxmaj despite some pretty solid performances by the actors , the story just does n't go anywhere . i think \" xxmaj xxunk \" would have been a better title for this .,xxbos xxmaj sorry . xxmaj someone has to say it . xxmaj this really is / was a dull movie . xxmaj worthy perhaps , but dull nonetheless . i nearly cried with boredom when watching it . xxmaj the acting is pretty dire , the story drawn out and predictable , the score and camera - work totally standard and unexciting . xxmaj it 's one of those movies you are not allowed to hate ( xxunk it is about disabled people ) but hate it i suspect nearly everyone does . xxmaj it is interesting that critics have been so kind to this movie . i suppose they too are not allowed to be objective . xxmaj this was made to win awards - which i remember it duly did . xxmaj but it was neither interesting nor entertaining . i have n't seen the play so can not compare .,xxbos xxmaj the original \" xxmaj vanishing xxmaj point \" was a great flick . xxmaj subtle motives , characters that seemed real and spontaneous . xxmaj the remake was terrible . xxmaj preachy , overtly obvious ; it missed the point as to why the original was a classic . xxmaj the black xxmaj charger was cool , but even that could n't rescue this flick . xxmaj why stick with a white xxmaj challenger ? i did n't think that was the best choice back in ' 71 . xxmaj some parts of the film were unintentionally hilarious . xxmaj like when xxmaj vigo was standing on a cliff overlooking the canyon after his \" xxmaj dream xxmaj quest \" . xxmaj his xxmaj indian pal was standing next to him . xxmaj vigo was only wearing his white briefs . i 'm sorry - it just looked silly - him surveying the vista in his xxmaj fruit of the xxmaj looms . xxmaj another scene was at the end - after the explosive crash into the xxunk - the announcer said that the impact was clocked at 180 mph . xxmaj then he mentions that the cops said his remains were n't found because he vaporized , but some people believe he bailed out and was hidden by friends in the crowd . xxmaj then it shows him rolling out of the car at 180 mph ! xxmaj first of all , you could n't open the car door at 180 mph . xxmaj secondly , the car would not continue to travel in a straight line for 100 xxunk . with nobody to steer it . xxmaj it would promptly roll over about 30 times . xxmaj thirdly , if you hit the pavement at 180 mph , you would wind up in various squishy pieces . xxmaj no matter , we see him at the end standing with his daughter . xxmaj all in all , a movie that would insult anyone 's intelligence .,xxbos xxmaj the 1960 's were a time of change and awakening for most people . xxmaj social upheaval and unrest were commonplace as people spoke - out about their views . xxmaj racial tensions , politics , the xxmaj vietnam xxmaj war , sexual promiscuity , and drug use were all part of the daily fabric , and the daily news . xxmaj this film attempted to encapsulate these historical aspects into an entertaining movie , and largely succeeded . \n",
              " \n",
              "  xxmaj in this film , two families are followed : one white , one black . xxmaj during the first half of the film , the story follows each family on a equal basis through social and family struggles . xxmaj unfortunately , the second half of the movie is nearly dedicated to the white family . xxmaj admittedly , there are more characters in this family , and the story lines are intermingled , but equal consideration is not given to the racial aspects of this century . \n",
              " \n",
              "  xxmaj on the whole , the acting is well done and historical footage is mixed with color and black and white original footage to give a documentary feel to the movie . xxmaj the movie is a work of fiction , but clips of well - known historical figures are used to set the time - line . \n",
              " \n",
              "  i enjoyed the movie but the situations were predictable and the storyline was one - sided .\n",
              "y: CategoryList\n",
              "neg,neg,neg,neg,neg\n",
              "Path: /root/.fastai/data/imdb;\n",
              "\n",
              "Valid: LabelList (25000 items)\n",
              "x: TextList\n",
              "xxbos \" xxmaj shade \" tries hard to be another \" xxmaj sting \" , substituting poker for horse racing as the means by which to bring down an enemy , but it fails miserably . \n",
              " \n",
              "  i watched the whole thing and still never could quite understand why the young kid wanted to double - cross his partner . xxmaj was it because his partner stole his girl ? xxmaj is there a woman in the world who is worth going to that much trouble over ? xxmaj if there is , it certainly was n't this shrew . xxmaj she had no redeeming qualities whatsoever , and really now , did she actually have a special room set up so that a surgeon could remove the kidney from whoever tried to pick her up in a bar ? xxmaj dina xxmaj merrill makes a short appearance as a rich woman who hosts , of all things , pay - the - rent poker parties at her palatial home . xxmaj and then the players say things like , \" i 'll see your thousand and raise you another five thousand . \" xxmaj give me a break . xxmaj you ca n't call ( \" see \" ) and raise , you do one or the other . xxmaj any kid playing for nickels and dimes at the kitchen table knows this ; you 'd think grown men playing for stakes this high -- or at least the knuckleheads who wrote the script -- would know it too . \n",
              " \n",
              "  xxmaj one of the other posters mentioned how no high - limit poker game would allow players to actually deal their own cards and i agree . xxmaj you do n't allow two of the best - known car cheats into a game where the buy - in is $ 250,000 and then let them deal to each other . xxmaj that 's not poker ; that 's just seeing which one can cheat better . xxmaj and i 'd like to know what person in his right mind would buy in to a game in which two of the best - known card cheats are playing and expect that he might have a chance at winning ? xxmaj and most of all , what xxmaj mafia boss would run such a game ? xxmaj every time xxmaj melanie xxmaj griffith came on the screen i was so mesmerized by those gigantic fluorescent red lips of hers that i completely lost the storyline , and seeing her and xxmaj stallone together was more like a public service announcement for plastic surgery gone wrong than a love connection . xxmaj stallone mentions that she used to be a grifter before she bought the restaurant she now runs , but we do n't know what kind of grifter she was and we never see her working with xxmaj stallone in their younger days so we are left to wonder , if we even care that much . \n",
              " \n",
              "  xxmaj jamie xxmaj foxx is the best character in the whole movie , but he gets killed off right off the bat and we 're left with cardboard cut - outs who all sound like they 're reading their lines off a teleprompter just off - camera . \n",
              " \n",
              "  xxmaj the ending makes no sense either . xxmaj the kid gets his cut from the game and just walks down the street with a briefcase full of money and his partner is nowhere to be seen ? xxmaj the xxmaj mafia is n't watching every move he makes ? xxmaj everyone else just shrugs their shoulders and quietly accepts the loss of millions of dollars without trying to recoup any of it ? i do n't think so . \n",
              " \n",
              "  xxmaj most of all , this movie does a great injustice to professional poker players all over the world , insinuating that the only way to win is by palming cards and playing with \" juiced \" decks . xxmaj and why is it they 're always palming kings and aces ? xxmaj sometimes you need a three or a nine to fill a straight or full house . \n",
              " \n",
              "  xxmaj the best parts of the whole film are the sleight - of - hand tricks during the beginning and ending credits ; everything in between is ridiculous .,xxbos xxmaj there is only one word that describes this film : xxup bad ! ! i have no idea why this movie was even made , or how they got xxmaj dennis xxmaj hopper to star in this film . xxmaj stuart xxmaj gordon is a better director than this and xxmaj hopper is a much better actor . xxmaj the film is plain stupid . i did like the \" square pigs \" idea and there was an interesting love scene involving a cyborg , other than that , avoid this film at all costs .,xxbos xxmaj to be hones , i used to like this show and watch it regularly , but now ( thank god ! ) i do n't understand why did i watch it . xxmaj sex and the city is one of the most pointless and insulting xxup tv shows i 've ever seen . i really do n't get the point of this show , despite of trying . xxmaj people are saying , that xxmaj sex and the city is funny . xxmaj in what way ? xxmaj by cursing all the time , talking about vibrators and the size of the penis ? xxmaj give me a break . \n",
              " \n",
              "  i do n't understand the plot : we have four girls who are trying to find a perfect man by sleeping with every dork , who comes around . xxmaj and this show is all about four spoiled chicks , who are sleeping with every man in the city , but in the end they admit the best pleasure comes out of the penis vibrators . xxmaj and yeah ... the show is trying to tell us , that sex is the most important thing in every relationship . xxmaj if you can have a good sex , you 're a good husband ( or wife ) . xxmaj it does n't matter if you want to be loyal and having a good heart .. the size does matter . \n",
              " \n",
              "  xxmaj the biggest problem is also bad acting . xxmaj the four main actresses ( xxmaj sarah xxmaj jessica xxmaj parker , xxmaj kim xxmaj xxunk , xxmaj cynthia xxmaj nixon and xxmaj kristin xxmaj davis ) are so bad and unconvincing , that it makes me sick just watching this show . xxmaj parker is just screaming and complaining all the time , xxmaj xxunk is showing her old boobs and saying \" the f - word \" all the time , xxmaj davis delivers her smile ( and nothing else ) and xxmaj nixon acts like she is bored all the time . xxmaj and yes ... men are sex - hungry pigs in this show . xxmaj but , judging by this show , women are not much better . xxmaj this show is insulting for men and women . xxmaj the women are shown so primitive and emotionless , like they do n't have any heart , just hunger for sex . xxmaj it 's insulting for everyone . \n",
              " \n",
              "  xxmaj sex and the city is one of the worst xxup tv shows and i 'm glad that the show ended , because it delivers bad acting and pointless stories . xxmaj the whole world is not all about sex and vibrators .,xxbos xxmaj well , i saw this movie during the last xxmaj san xxmaj sebastian xxmaj film xxmaj festival . xxmaj the reaction to it was ... let 's say as funny as the movie xxunk is . xxmaj it happened that they showed a copy with terribly wrong spanish subtitles . xxmaj they seemed to be a translation from chinese to english and then to spanish . xxmaj it was all confusing , the genders were switched ( girls appeared as boys and boys as girls ) , and my friends and i remember great lines ... but because they were so absurd . xxmaj all in all not a good movie , but if they ever show it on tv , and you have nothing to do , and if you want to laugh ( again , not so much with the movie ) then go ahead , \" xxmaj visible secret \" is your film .,xxbos xxmaj well , first of all , excuse me for the lame pun in the title . i was browsing for movies to rent the other day and saw this . i heard something about this so i picked it up and looked on the back and there was a short little review blurb on it from xxmaj john xxmaj fallon xxup aka xxmaj arrow in the xxmaj head ! xxmaj at that moment i thought \" xxmaj well if he likes it then i got ta like it ! \" xxmaj so i rented it and just finally got around to watching it last night ( college keeps me so busy ) . xxmaj oh and i might wanna add that i read a little of xxmaj arrow 's review and it turns out that out of 4 stars he gave it 1 and a half . xxmaj so my expectations from this movie went from very high to iffy . xxmaj well after watching this , i once again agree with xxmaj arrow ( and turns out that quote from the review was the only positive thing he said about that ! ) xxmaj wow , did this film stink or what ? xxmaj where do i begin with why it did so ? xxmaj well , the film was so dull in my opinion . xxmaj not even the cool gore bits excited me and when a decapitation does n't excite you in a movie , that 's bad ! xxmaj the characters i hated a lot and from the beginning i could tell who would die and who would n't . xxmaj actually the film proved me wrong at some points , but the worst thing is that one particular character i wanted to die did n't ! xxmaj what the heck ? xxmaj and the chemistry between the main girl and the guy she met ? xxmaj did n't feel it . xxmaj he obviously was just there to be eye candy and give her a love interest , otherwise i thought he was a waste ! xxmaj and as a horror fan i should know that doing the \" dumb horror movie \" sometimes got ta happen or else there would n't be much of a movie , but the ones in here ticked me off ! xxmaj hello ? xxmaj why are you making out in the room of the killer nun when you should be on the lookout from her ? xxmaj and it was done by the supposedly smarter characters no less . xxmaj the twist xxrep 4 . ah , it would have been alright , if it had n't been done a billion times and i did n't have to sit through this wast of film to reach that point ! xxmaj my main point : xxmaj stupid movie that sucked me in with some words of my favorite ( actually my only favorite ) movie critic . xxmaj jerks !\n",
              "y: CategoryList\n",
              "neg,neg,neg,neg,neg\n",
              "Path: /root/.fastai/data/imdb;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(60000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f48b046f400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (25000 items)\n",
              "x: TextList\n",
              "xxbos ' i do n't understand . xxmaj none of this makes any sense ! ' , exclaims one exasperated character towards the end of xxmaj death xxmaj smiles at xxmaj murder . xxmaj having just sat through this thoroughly confusing mess of a movie , i know exactly how he feels . xxmaj the story , by the film 's director xxmaj aristide xxmaj xxunk ( good old xxmaj joe xxmaj d'amato using his real name for a change ) , is a clumsy mix of the supernatural , murder / mystery , and pretentious arty rubbish , the likes of which will probably appeal to those who admire trippy 70s garbage such as xxmaj jess xxmaj franco 's more bizarre efforts , but which had me struggling to remain conscious . \n",
              " \n",
              "  xxmaj opening with a hunchback mourning the death of his beautiful sister ( with whom he had been having an incestuous affair , before eventually losing her to a dashing doctor ) , xxmaj death xxmaj smiles at xxmaj murder soon becomes very confusing when the very same woman ( played by xxmaj ewa xxmaj aulin , who stars in the equally strange ' xxmaj death xxmaj laid an xxmaj egg ' ) is seen alive and kicking , the sole survivor of a coach accident that occurs outside the estate of xxmaj walter and xxmaj eva von xxmaj xxunk . xxmaj after being invited to stay and recuperate in their home , where she is tended to by creepy xxmaj dr. xxmaj sturges ( xxmaj klaus xxmaj kinski in a throwaway role ) , the comely lass begins love affairs with both xxmaj mr. and xxmaj mrs. xxmaj xxunk ( meaning that viewers are treated to some brief but welcome scenes of nookie and lesbian lovin' ) . \n",
              " \n",
              "  ' xxmaj so far , so good ' , i thought to myself at this point , ' we 've had xxunk , incest , some blood and guts , and gratuitous female xxunk ingredients of a great trashy xxmaj euro - horror ; what follows , however , is a lame attempt by xxmaj xxunk to combine giallo style killings , ghostly goings on , and even elements from xxmaj edgar xxmaj allan xxmaj poe 's ' xxmaj the xxmaj black xxmaj cat ' , to tell a very silly , utterly bewildering , and ultimately extremely boring tale of revenge from beyond the grave . \n",
              " \n",
              "  xxmaj this film seems to have quite few admirers here on imdb , but given the choice , i would much rather watch one of the director 's sleazier movies from later in his career ; i guess incomprehensible , meandering , surreal 70s xxmaj gothic horror just ai n't my thing ! 2.5 out of 10 ( purely for the cheesy gore and xxunk ) , rounded up to 3 for imdb .,xxbos xxmaj this movie seemed like it was going to be better than it ended up being . xxmaj the cinematography is good , the acting seemed solid , the dialogue was n't too stiff ... but then about twenty minutes in there 's this long scene with a xxmaj doctor who you know is actually a patient at the asylum pretending to be a xxmaj doctor - and it just goes south from there . \n",
              " \n",
              "  xxmaj on top of that , the demon is about the silliest looking xxunk since the xxmaj godzilla - looking thing in xxmaj curse of the xxmaj demon . xxmaj there 's also some odd demon worshippers who wear masks that look like the exploding teens from the beginning of xxmaj logan 's xxmaj run . \n",
              " \n",
              "  xxmaj in the end , the cinematography could n't save this movie . xxmaj despite some pretty solid performances by the actors , the story just does n't go anywhere . i think \" xxmaj xxunk \" would have been a better title for this .,xxbos xxmaj sorry . xxmaj someone has to say it . xxmaj this really is / was a dull movie . xxmaj worthy perhaps , but dull nonetheless . i nearly cried with boredom when watching it . xxmaj the acting is pretty dire , the story drawn out and predictable , the score and camera - work totally standard and unexciting . xxmaj it 's one of those movies you are not allowed to hate ( xxunk it is about disabled people ) but hate it i suspect nearly everyone does . xxmaj it is interesting that critics have been so kind to this movie . i suppose they too are not allowed to be objective . xxmaj this was made to win awards - which i remember it duly did . xxmaj but it was neither interesting nor entertaining . i have n't seen the play so can not compare .,xxbos xxmaj the original \" xxmaj vanishing xxmaj point \" was a great flick . xxmaj subtle motives , characters that seemed real and spontaneous . xxmaj the remake was terrible . xxmaj preachy , overtly obvious ; it missed the point as to why the original was a classic . xxmaj the black xxmaj charger was cool , but even that could n't rescue this flick . xxmaj why stick with a white xxmaj challenger ? i did n't think that was the best choice back in ' 71 . xxmaj some parts of the film were unintentionally hilarious . xxmaj like when xxmaj vigo was standing on a cliff overlooking the canyon after his \" xxmaj dream xxmaj quest \" . xxmaj his xxmaj indian pal was standing next to him . xxmaj vigo was only wearing his white briefs . i 'm sorry - it just looked silly - him surveying the vista in his xxmaj fruit of the xxmaj looms . xxmaj another scene was at the end - after the explosive crash into the xxunk - the announcer said that the impact was clocked at 180 mph . xxmaj then he mentions that the cops said his remains were n't found because he vaporized , but some people believe he bailed out and was hidden by friends in the crowd . xxmaj then it shows him rolling out of the car at 180 mph ! xxmaj first of all , you could n't open the car door at 180 mph . xxmaj secondly , the car would not continue to travel in a straight line for 100 xxunk . with nobody to steer it . xxmaj it would promptly roll over about 30 times . xxmaj thirdly , if you hit the pavement at 180 mph , you would wind up in various squishy pieces . xxmaj no matter , we see him at the end standing with his daughter . xxmaj all in all , a movie that would insult anyone 's intelligence .,xxbos xxmaj the 1960 's were a time of change and awakening for most people . xxmaj social upheaval and unrest were commonplace as people spoke - out about their views . xxmaj racial tensions , politics , the xxmaj vietnam xxmaj war , sexual promiscuity , and drug use were all part of the daily fabric , and the daily news . xxmaj this film attempted to encapsulate these historical aspects into an entertaining movie , and largely succeeded . \n",
              " \n",
              "  xxmaj in this film , two families are followed : one white , one black . xxmaj during the first half of the film , the story follows each family on a equal basis through social and family struggles . xxmaj unfortunately , the second half of the movie is nearly dedicated to the white family . xxmaj admittedly , there are more characters in this family , and the story lines are intermingled , but equal consideration is not given to the racial aspects of this century . \n",
              " \n",
              "  xxmaj on the whole , the acting is well done and historical footage is mixed with color and black and white original footage to give a documentary feel to the movie . xxmaj the movie is a work of fiction , but clips of well - known historical figures are used to set the time - line . \n",
              " \n",
              "  i enjoyed the movie but the situations were predictable and the storyline was one - sided .\n",
              "y: CategoryList\n",
              "neg,neg,neg,neg,neg\n",
              "Path: /root/.fastai/data/imdb;\n",
              "\n",
              "Valid: LabelList (25000 items)\n",
              "x: TextList\n",
              "xxbos \" xxmaj shade \" tries hard to be another \" xxmaj sting \" , substituting poker for horse racing as the means by which to bring down an enemy , but it fails miserably . \n",
              " \n",
              "  i watched the whole thing and still never could quite understand why the young kid wanted to double - cross his partner . xxmaj was it because his partner stole his girl ? xxmaj is there a woman in the world who is worth going to that much trouble over ? xxmaj if there is , it certainly was n't this shrew . xxmaj she had no redeeming qualities whatsoever , and really now , did she actually have a special room set up so that a surgeon could remove the kidney from whoever tried to pick her up in a bar ? xxmaj dina xxmaj merrill makes a short appearance as a rich woman who hosts , of all things , pay - the - rent poker parties at her palatial home . xxmaj and then the players say things like , \" i 'll see your thousand and raise you another five thousand . \" xxmaj give me a break . xxmaj you ca n't call ( \" see \" ) and raise , you do one or the other . xxmaj any kid playing for nickels and dimes at the kitchen table knows this ; you 'd think grown men playing for stakes this high -- or at least the knuckleheads who wrote the script -- would know it too . \n",
              " \n",
              "  xxmaj one of the other posters mentioned how no high - limit poker game would allow players to actually deal their own cards and i agree . xxmaj you do n't allow two of the best - known car cheats into a game where the buy - in is $ 250,000 and then let them deal to each other . xxmaj that 's not poker ; that 's just seeing which one can cheat better . xxmaj and i 'd like to know what person in his right mind would buy in to a game in which two of the best - known card cheats are playing and expect that he might have a chance at winning ? xxmaj and most of all , what xxmaj mafia boss would run such a game ? xxmaj every time xxmaj melanie xxmaj griffith came on the screen i was so mesmerized by those gigantic fluorescent red lips of hers that i completely lost the storyline , and seeing her and xxmaj stallone together was more like a public service announcement for plastic surgery gone wrong than a love connection . xxmaj stallone mentions that she used to be a grifter before she bought the restaurant she now runs , but we do n't know what kind of grifter she was and we never see her working with xxmaj stallone in their younger days so we are left to wonder , if we even care that much . \n",
              " \n",
              "  xxmaj jamie xxmaj foxx is the best character in the whole movie , but he gets killed off right off the bat and we 're left with cardboard cut - outs who all sound like they 're reading their lines off a teleprompter just off - camera . \n",
              " \n",
              "  xxmaj the ending makes no sense either . xxmaj the kid gets his cut from the game and just walks down the street with a briefcase full of money and his partner is nowhere to be seen ? xxmaj the xxmaj mafia is n't watching every move he makes ? xxmaj everyone else just shrugs their shoulders and quietly accepts the loss of millions of dollars without trying to recoup any of it ? i do n't think so . \n",
              " \n",
              "  xxmaj most of all , this movie does a great injustice to professional poker players all over the world , insinuating that the only way to win is by palming cards and playing with \" juiced \" decks . xxmaj and why is it they 're always palming kings and aces ? xxmaj sometimes you need a three or a nine to fill a straight or full house . \n",
              " \n",
              "  xxmaj the best parts of the whole film are the sleight - of - hand tricks during the beginning and ending credits ; everything in between is ridiculous .,xxbos xxmaj there is only one word that describes this film : xxup bad ! ! i have no idea why this movie was even made , or how they got xxmaj dennis xxmaj hopper to star in this film . xxmaj stuart xxmaj gordon is a better director than this and xxmaj hopper is a much better actor . xxmaj the film is plain stupid . i did like the \" square pigs \" idea and there was an interesting love scene involving a cyborg , other than that , avoid this film at all costs .,xxbos xxmaj to be hones , i used to like this show and watch it regularly , but now ( thank god ! ) i do n't understand why did i watch it . xxmaj sex and the city is one of the most pointless and insulting xxup tv shows i 've ever seen . i really do n't get the point of this show , despite of trying . xxmaj people are saying , that xxmaj sex and the city is funny . xxmaj in what way ? xxmaj by cursing all the time , talking about vibrators and the size of the penis ? xxmaj give me a break . \n",
              " \n",
              "  i do n't understand the plot : we have four girls who are trying to find a perfect man by sleeping with every dork , who comes around . xxmaj and this show is all about four spoiled chicks , who are sleeping with every man in the city , but in the end they admit the best pleasure comes out of the penis vibrators . xxmaj and yeah ... the show is trying to tell us , that sex is the most important thing in every relationship . xxmaj if you can have a good sex , you 're a good husband ( or wife ) . xxmaj it does n't matter if you want to be loyal and having a good heart .. the size does matter . \n",
              " \n",
              "  xxmaj the biggest problem is also bad acting . xxmaj the four main actresses ( xxmaj sarah xxmaj jessica xxmaj parker , xxmaj kim xxmaj xxunk , xxmaj cynthia xxmaj nixon and xxmaj kristin xxmaj davis ) are so bad and unconvincing , that it makes me sick just watching this show . xxmaj parker is just screaming and complaining all the time , xxmaj xxunk is showing her old boobs and saying \" the f - word \" all the time , xxmaj davis delivers her smile ( and nothing else ) and xxmaj nixon acts like she is bored all the time . xxmaj and yes ... men are sex - hungry pigs in this show . xxmaj but , judging by this show , women are not much better . xxmaj this show is insulting for men and women . xxmaj the women are shown so primitive and emotionless , like they do n't have any heart , just hunger for sex . xxmaj it 's insulting for everyone . \n",
              " \n",
              "  xxmaj sex and the city is one of the worst xxup tv shows and i 'm glad that the show ended , because it delivers bad acting and pointless stories . xxmaj the whole world is not all about sex and vibrators .,xxbos xxmaj well , i saw this movie during the last xxmaj san xxmaj sebastian xxmaj film xxmaj festival . xxmaj the reaction to it was ... let 's say as funny as the movie xxunk is . xxmaj it happened that they showed a copy with terribly wrong spanish subtitles . xxmaj they seemed to be a translation from chinese to english and then to spanish . xxmaj it was all confusing , the genders were switched ( girls appeared as boys and boys as girls ) , and my friends and i remember great lines ... but because they were so absurd . xxmaj all in all not a good movie , but if they ever show it on tv , and you have nothing to do , and if you want to laugh ( again , not so much with the movie ) then go ahead , \" xxmaj visible secret \" is your film .,xxbos xxmaj well , first of all , excuse me for the lame pun in the title . i was browsing for movies to rent the other day and saw this . i heard something about this so i picked it up and looked on the back and there was a short little review blurb on it from xxmaj john xxmaj fallon xxup aka xxmaj arrow in the xxmaj head ! xxmaj at that moment i thought \" xxmaj well if he likes it then i got ta like it ! \" xxmaj so i rented it and just finally got around to watching it last night ( college keeps me so busy ) . xxmaj oh and i might wanna add that i read a little of xxmaj arrow 's review and it turns out that out of 4 stars he gave it 1 and a half . xxmaj so my expectations from this movie went from very high to iffy . xxmaj well after watching this , i once again agree with xxmaj arrow ( and turns out that quote from the review was the only positive thing he said about that ! ) xxmaj wow , did this film stink or what ? xxmaj where do i begin with why it did so ? xxmaj well , the film was so dull in my opinion . xxmaj not even the cool gore bits excited me and when a decapitation does n't excite you in a movie , that 's bad ! xxmaj the characters i hated a lot and from the beginning i could tell who would die and who would n't . xxmaj actually the film proved me wrong at some points , but the worst thing is that one particular character i wanted to die did n't ! xxmaj what the heck ? xxmaj and the chemistry between the main girl and the guy she met ? xxmaj did n't feel it . xxmaj he obviously was just there to be eye candy and give her a love interest , otherwise i thought he was a waste ! xxmaj and as a horror fan i should know that doing the \" dumb horror movie \" sometimes got ta happen or else there would n't be much of a movie , but the ones in here ticked me off ! xxmaj hello ? xxmaj why are you making out in the room of the killer nun when you should be on the lookout from her ? xxmaj and it was done by the supposedly smarter characters no less . xxmaj the twist xxrep 4 . ah , it would have been alright , if it had n't been done a billion times and i did n't have to sit through this wast of film to reach that point ! xxmaj my main point : xxmaj stupid movie that sucked me in with some words of my favorite ( actually my only favorite ) movie critic . xxmaj jerks !\n",
              "y: CategoryList\n",
              "neg,neg,neg,neg,neg\n",
              "Path: /root/.fastai/data/imdb;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(60000, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f48b046f400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(60000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(60000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(60000, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(60000, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFRdavT6Oy_v",
        "colab_type": "code",
        "outputId": "ebd46ffc-9cfc-47b4-fede-5d2a2a131b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='94' class='' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      18.08% [94/520 00:15<01:12 1.7461]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnn3KuOBOy_x",
        "colab_type": "code",
        "outputId": "2b1c051c-42a7-4444-a39c-f16f1ab4da6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hws06HJ3Oy_0",
        "colab_type": "code",
        "outputId": "c7d37c93-1d15-4784-b924-db69cd2199b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.264844</td>\n",
              "      <td>0.180140</td>\n",
              "      <td>0.931800</td>\n",
              "      <td>03:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j107iRnOy_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('first')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJgqwTqiOy_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('first');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y0VVW1vOy_8",
        "colab_type": "code",
        "outputId": "91e3b00d-6f79-4b49-cfe7-42a1e1a49609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.237734</td>\n",
              "      <td>0.159021</td>\n",
              "      <td>0.940720</td>\n",
              "      <td>03:28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFyg02gpOy_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('second')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW4ZWrraOy__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('second');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGzPdufqOzAB",
        "colab_type": "code",
        "outputId": "104579b3-ba17-44dc-9a09-7e5dcdefdb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.195377</td>\n",
              "      <td>0.140547</td>\n",
              "      <td>0.947920</td>\n",
              "      <td>04:23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5FxWqsSOzAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('third')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2yCTDXdOzAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.load('third');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIIHCaMhOzAJ",
        "colab_type": "code",
        "outputId": "9ccbd958-ac3b-402d-debd-70d7c817533e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.162599</td>\n",
              "      <td>0.137945</td>\n",
              "      <td>0.949640</td>\n",
              "      <td>06:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.143126</td>\n",
              "      <td>0.144035</td>\n",
              "      <td>0.948560</td>\n",
              "      <td>05:25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YhTZ1yoOzAM",
        "colab_type": "code",
        "outputId": "96a16127-5d01-4bf7-fd4e-064f793888b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"I really loved that movie, it was awesome!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([1.8866e-04, 9.9981e-01]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT_K1AbQOzAQ",
        "colab_type": "code",
        "outputId": "23d02a79-1cc4-4495-9967-d42cd64f622a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data.classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative', 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyyj3pGHY6sn",
        "colab_type": "code",
        "outputId": "405bd417-54d0-464a-df6c-6f52cc24948f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"I didn't like the movie, the picture was good but not good enough!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(0), tensor(0), tensor([0.8958, 0.1042]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlrx606MY6wB",
        "colab_type": "code",
        "outputId": "44ea76cb-cb58-4f60-a31e-a6c5a65e9ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"I learned so many things that I didn't know before so worth it all\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.0842, 0.9158]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxonqaTjZkRc",
        "colab_type": "code",
        "outputId": "038c60b9-4950-4d8b-bad5-f536e47ac905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"In the end, the subject is as simple as it is regressive: lucky Americans, stay home.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.2795, 0.7205]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTj-adiUahIS",
        "colab_type": "code",
        "outputId": "db43cf50-6cc6-43a2-da71-40a71d552d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"It’s fun, at first, partly because something feels distinctly off, like milk that’s just gone bad. (You don’t know how bad until you taste it.)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(0), tensor(0), tensor([0.6280, 0.3720]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}